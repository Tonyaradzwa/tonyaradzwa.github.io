{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d08c513",
   "metadata": {},
   "source": [
    "# Predicting parts of speech with an LSTM\n",
    "\n",
    "Let's preview the end result. We want to take a sentence and output the part of speech for each word in that sentence. Something like this:\n",
    "\n",
    "**Code**\n",
    "\n",
    "```python\n",
    "new_sentence = \"I is a teeth\"\n",
    "\n",
    "...\n",
    "\n",
    "predictions = model(processed_sentence)\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "**Output**\n",
    "\n",
    "```text\n",
    "I     => Noun\n",
    "is    => Verb\n",
    "a     => Determiner\n",
    "teeth => Noun\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31b2ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps(s):\n",
    "    \"\"\"Process String: convert a string into a list of lowercased words.\"\"\"\n",
    "    return [word.strip() for word in re.split(r'([+-/*()?]|\\s+)', s) if word.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86b2051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# read quesitons and answers from file\n",
    "dataset_filename = Path(\"../train_data/arithmetic__mixed.txt\")\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "with open(dataset_filename) as dataset_file:\n",
    "    # Grabbing a subset of the entire file\n",
    "    for i in range(100):\n",
    "        line_q = dataset_file.readline().strip()\n",
    "        line_a = dataset_file.readline().strip()\n",
    "\n",
    "        questions.append(ps(line_q))\n",
    "        answers.append(eval(line_a))\n",
    "    \n",
    "# use zip to create dataset object\n",
    "dataset = [(q,a) for q,a in zip(questions,answers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "699caa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855326b",
   "metadata": {},
   "source": [
    "## Preparing data for use as NN input\n",
    "\n",
    "We can't pass a list of plain text words and tags to a NN. We need to convert them to a more appropriate format.\n",
    "\n",
    "We'll start by creating a unique index for each word and tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63e114fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {}\n",
    "\n",
    "total_words = 0\n",
    "\n",
    "\n",
    "for question, _ in dataset:\n",
    "\n",
    "    total_words += len(question)\n",
    "\n",
    "    for word in question:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a91d625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Vocabulary Indices\n",
      "-------------------------------\n",
      "             ( =>  2\n",
      "             ) =>  6\n",
      "             * => 25\n",
      "             + =>  1\n",
      "             - =>  4\n",
      "             . => 18\n",
      "             / =>  7\n",
      "             0 => 48\n",
      "             1 =>  8\n",
      "            10 =>  9\n",
      "           100 => 46\n",
      "          1008 => 94\n",
      "          1017 => 123\n",
      "           102 => 95\n",
      "           104 => 68\n",
      "           105 => 75\n",
      "           108 => 127\n",
      "            11 => 83\n",
      "           114 => 56\n",
      "           118 => 116\n",
      "            12 => 14\n",
      "           120 => 111\n",
      "           122 => 60\n",
      "           126 => 126\n",
      "          1271 => 27\n",
      "            13 => 89\n",
      "           130 => 113\n",
      "           133 => 82\n",
      "           135 => 132\n",
      "          1368 => 108\n",
      "            14 => 11\n",
      "           140 => 97\n",
      "           142 => 58\n",
      "           145 => 129\n",
      "            15 =>  0\n",
      "            16 => 20\n",
      "           160 => 79\n",
      "         16095 => 131\n",
      "           164 => 88\n",
      "           168 => 125\n",
      "            17 =>  5\n",
      "           174 => 23\n",
      "            18 => 40\n",
      "           180 => 43\n",
      "           182 => 69\n",
      "           188 => 114\n",
      "            19 => 72\n",
      "           198 => 15\n",
      "             2 => 29\n",
      "            20 => 33\n",
      "           200 => 112\n",
      "          2016 => 104\n",
      "           203 => 24\n",
      "            21 => 61\n",
      "           210 => 103\n",
      "           225 => 133\n",
      "           228 => 91\n",
      "          2296 => 28\n",
      "            24 => 12\n",
      "            25 => 34\n",
      "            26 => 52\n",
      "          2625 => 74\n",
      "            27 => 39\n",
      "            28 => 110\n",
      "           287 => 99\n",
      "             3 => 26\n",
      "            30 => 38\n",
      "            31 => 65\n",
      "           315 => 44\n",
      "          3198 => 90\n",
      "            32 => 115\n",
      "           320 => 77\n",
      "           329 => 120\n",
      "            33 => 109\n",
      "          3325 => 63\n",
      "            34 => 36\n",
      "           341 => 84\n",
      "            35 => 80\n",
      "            36 => 100\n",
      "            39 => 45\n",
      "             4 => 22\n",
      "            40 => 62\n",
      "           400 => 73\n",
      "            42 => 53\n",
      "           432 => 66\n",
      "            44 => 85\n",
      "           444 => 130\n",
      "            45 => 96\n",
      "           460 => 106\n",
      "            48 => 78\n",
      "           492 => 98\n",
      "           495 => 86\n",
      "           497 => 59\n",
      "             5 => 21\n",
      "            50 => 124\n",
      "            51 => 54\n",
      "            54 => 67\n",
      "            56 => 47\n",
      "           560 => 76\n",
      "           565 => 122\n",
      "            57 => 64\n",
      "            58 => 87\n",
      "             6 => 37\n",
      "            60 => 10\n",
      "           600 => 16\n",
      "            65 => 70\n",
      "            66 => 105\n",
      "           665 => 107\n",
      "           675 => 101\n",
      "             7 =>  3\n",
      "            70 => 102\n",
      "          7011 => 92\n",
      "           738 => 117\n",
      "            75 => 121\n",
      "            76 => 57\n",
      "            78 => 41\n",
      "             8 => 55\n",
      "            82 => 118\n",
      "            83 => 119\n",
      "            84 => 71\n",
      "           861 => 93\n",
      "            87 => 128\n",
      "             9 => 30\n",
      "            92 => 42\n",
      "            98 => 81\n",
      "            99 => 17\n",
      "             ? => 35\n",
      "     Calculate => 13\n",
      "      Evaluate => 19\n",
      "          What => 31\n",
      "            is => 32\n",
      "            of => 51\n",
      "           the => 49\n",
      "         value => 50\n",
      "\n",
      "Total number of words: 1772\n",
      "Number of unique words: 134\n"
     ]
    }
   ],
   "source": [
    "print(\"       Vocabulary Indices\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "for word in sorted(word_to_index):\n",
    "    print(f\"{word:>14} => {word_to_index[word]:>2}\")\n",
    "\n",
    "print(\"\\nTotal number of words:\", total_words)\n",
    "print(\"Number of unique words:\", len(word_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833357a4",
   "metadata": {},
   "source": [
    "## Letting the NN parameterize words\n",
    "\n",
    "Once we have a unique identifier for each word, it is useful to start our NN with an [embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding) layer. This layer converts an index into a vector of values.\n",
    "\n",
    "You can think of each value as indicating something about the word. For example, maybe the first value indicates how much a word conveys happiness vs sadness. Of course, the NN can learn any attributes and it is not limited to thinks like happy/sad, masculine/feminine, etc.\n",
    "\n",
    "**Creating an embedding layer**. An embedding layer is created by telling it the size of the vocabulary (the number of words) and an embedding dimension (how many values to use to represent a word).\n",
    "\n",
    "**Embedding layer input and output**. An embedding layer takes an index and return a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71a695b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_index_tensor(words, mapping):\n",
    "    indices = [mapping[w] for w in words]\n",
    "    return torch.tensor(indices, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d20c8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_index)\n",
    "embed_dim = 6  # Hyperparameter\n",
    "embed_layer = torch.nn.Embedding(vocab_size, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24739098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8]),\n",
       " torch.Size([8, 6]),\n",
       " tensor([[ 0.2501, -2.8750, -1.2397, -0.2463,  0.4269,  0.1939],\n",
       "         [ 0.5214, -1.0744, -0.7274, -0.1141, -1.5100,  1.3529],\n",
       "         [ 0.4006, -1.2748,  0.4613,  0.4768,  1.0093, -0.8007],\n",
       "         [-0.2955, -1.2805,  1.4766,  2.4918, -0.7018,  0.5850],\n",
       "         [ 0.5214, -1.0744, -0.7274, -0.1141, -1.5100,  1.3529],\n",
       "         [ 1.5796,  0.5732, -0.2109, -0.2669,  0.6263,  0.5662],\n",
       "         [-1.4162,  1.0356,  1.2853,  1.0460, -0.0742,  0.0235],\n",
       "         [-1.0383, -0.4141, -0.4091, -0.4082,  0.5619, -0.7488]],\n",
       "        grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i = torch.tensor([word_to_index[\"the\"], word_to_index[\"dog\"]])\n",
    "indices = convert_to_index_tensor(ps(\"15 + (7 + -17)\"), word_to_index)\n",
    "embed_output = embed_layer(indices)\n",
    "indices.shape, embed_output.shape, embed_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e167a05",
   "metadata": {},
   "source": [
    "## Adding an LSTM layer\n",
    "\n",
    "The [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) layer is in charge of processing embeddings such that the network can output the correct classification. Since this is a recurrent layer, it will take into account past words when it creates an output for the current word.\n",
    "\n",
    "**Creating an LSTM layer**. To create an LSTM you need to tell it the size of its input (the size of an embedding) and the size of its internal cell state.\n",
    "\n",
    "**LSTM layer input and output**. An LSTM takes an embedding (and optionally an initial hidden and cell state) and outputs a value for each word as well as the current hidden and cell state).\n",
    "\n",
    "If you read the linked LSTM documentation you will see that it requires input in this format: (seq_len, batch, input_size)\n",
    "\n",
    "As you can see above, our embedding layer outputs something that is (seq_len, input_size). So, we need to add a dimension in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4284a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 10  # Hyperparameter\n",
    "num_layers = 5  # Hyperparameter\n",
    "lstm_layer = torch.nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "486bb0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 10])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The LSTM layer expects the input to be in the shape (L, N, E)\n",
    "#   L is the length of the sequence\n",
    "#   N is the batch size (we'll stick with 1 here)\n",
    "#   E is the size of the embedding\n",
    "lstm_output, _ = lstm_layer(embed_output.unsqueeze(1))\n",
    "lstm_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655160d",
   "metadata": {},
   "source": [
    "## Classifiying the LSTM output\n",
    "\n",
    "We can now add a fully connected, [linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear) layer to our NN to learn the correct part of speech (classification).\n",
    "\n",
    "**Creating a linear layer**. We create a linear layer by specifying the shape of the input into the layer and the number of neurons in the linear layer.\n",
    "\n",
    "**Linear layer input and output**. The input is expected to be (input_size, output_size) and the output will be the output of each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75440441",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = torch.nn.Linear(hidden_dim, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aefce339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 1]),\n",
       " tensor([[[-0.1192]],\n",
       " \n",
       "         [[-0.1279]],\n",
       " \n",
       "         [[-0.1367]],\n",
       " \n",
       "         [[-0.1424]],\n",
       " \n",
       "         [[-0.1455]],\n",
       " \n",
       "         [[-0.1471]],\n",
       " \n",
       "         [[-0.1478]],\n",
       " \n",
       "         [[-0.1483]]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output = linear_layer(lstm_output)\n",
    "linear_output.shape, linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566eb1a2",
   "metadata": {},
   "source": [
    "# Training an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f687b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "valid_percent = 0.2  # Training/validation split\n",
    "\n",
    "embed_dim = 7  # Size of word embedding\n",
    "hidden_dim = 8  # Size of LSTM internal state\n",
    "num_layers = 5  # Number of LSTM layers\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27273ef",
   "metadata": {},
   "source": [
    "## Creating training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f53886c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 80)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(dataset)\n",
    "vocab_size = len(word_to_index)  # Number of unique input words\n",
    "\n",
    "# Shuffle the data so that we can split the dataset randomly\n",
    "shuffle(dataset)\n",
    "\n",
    "split_point = int(N * valid_percent)\n",
    "valid_dataset = dataset[:split_point]\n",
    "train_dataset = dataset[split_point:]\n",
    "\n",
    "len(valid_dataset), len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69bd9c",
   "metadata": {},
   "source": [
    "## Creating the Parts of Speech LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3293433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POS_LSTM(torch.nn.Module):\n",
    "    \"\"\"Part of Speach LSTM model.\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.embed = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = torch.nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers)\n",
    "        self.linear = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.embed(X)\n",
    "        X, _ = self.lstm(X.unsqueeze(1))\n",
    "        return self.linear(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee5bc3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94c09deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(dataset):\n",
    "    \"\"\"A helper function for computing accuracy on the given dataset.\"\"\"\n",
    "    total_words = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sentence, tags in dataset:\n",
    "            sentence_indices = convert_to_index_tensor(sentence, word_to_index)\n",
    "            tag_scores = model(sentence_indices).squeeze()\n",
    "            predictions = tag_scores.argmax(dim=1)\n",
    "            total_words += len(sentence)\n",
    "            total_correct += sum(t == tag_list[p] for t, p in zip(tags, predictions))\n",
    "\n",
    "    return total_correct / total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c875a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/80 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4151236/175569527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/cs152/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/mambaforge/envs/cs152/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1151\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001b[0;32m/opt/mambaforge/envs/cs152/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2846\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "model = POS_LSTM(vocab_size, embed_dim, hidden_dim, num_layers)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "mb = master_bar(range(num_epochs))\n",
    "\n",
    "# accuracy = compute_accuracy(valid_dataset)\n",
    "# print(f\"Validation accuracy before training : {accuracy * 100:.2f}%\")\n",
    "\n",
    "for epoch in mb:\n",
    "\n",
    "    # Shuffle the data for each epoch (stochastic gradient descent)\n",
    "    shuffle(train_dataset)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for sentence, answer in progress_bar(train_dataset, parent=mb):\n",
    "        model.zero_grad()\n",
    "        \n",
    "        sentence = convert_to_index_tensor(sentence, word_to_index)\n",
    "\n",
    "        predict = model(sentence)\n",
    "        \n",
    "        print(predict[-1].shape)\n",
    "        print(torch.tensor([answer], dtype=torch.float).shape)\n",
    "        loss = criterion(predict[-1].squeeze(), torch.tensor([answer], dtype=torch.float))\n",
    "\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "\n",
    "#accuracy = compute_accuracy(valid_dataset)\n",
    "#print(f\"Validation accuracy after training : {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e780e3",
   "metadata": {},
   "source": [
    "## Examining results\n",
    "\n",
    "Here we look at all words that are misclassified by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edc42165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mis-predictions after training on entire dataset\n",
      "     Word      | True Tag | Prediction\n",
      "--------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4151236/3784395054.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0msentence_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_index_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtag_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "print(\"\\nMis-predictions after training on entire dataset\")\n",
    "header = \"Word\".center(14) + \" | True Tag | Prediction\"\n",
    "print(header)\n",
    "print(\"-\" * len(header))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sentence, tags in dataset:\n",
    "        sentence_indices = convert_to_index_tensor(sentence, word_to_index)\n",
    "        tag_scores = model(sentence_indices)\n",
    "        predictions = tag_scores.squeeze().argmax(dim=1)\n",
    "        for word, tag, pred in zip(sentence, tags, predictions):\n",
    "            if tag != tag_list[pred]:\n",
    "                print(f\"{word:>14} |     {tag}    |    {tag_list[pred]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf48486",
   "metadata": {},
   "source": [
    "## Using the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc88aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 => 7\n",
      "+ => 7\n",
      "3 => 7\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"3 + 3\"\n",
    "\n",
    "# Convert sentence to lowercase words\n",
    "sentence = ps(new_sentence)\n",
    "\n",
    "# Check that each word is in our vocabulary\n",
    "for word in sentence:\n",
    "    assert word in word_to_index\n",
    "\n",
    "# Convert input to a tensor\n",
    "sentence = convert_to_index_tensor(sentence, word_to_index)\n",
    "\n",
    "# Compute prediction\n",
    "predictions = model(sentence)\n",
    "predictions = predictions.squeeze().argmax(dim=1)\n",
    "\n",
    "# Print results\n",
    "for word, tag in zip(ps(new_sentence), predictions):\n",
    "    print(word, \"=>\", tag_list[tag.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03126959",
   "metadata": {},
   "source": [
    "Things to try:\n",
    "\n",
    "- compare with fully connected network\n",
    "- compare with CNN\n",
    "- compare with transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d17307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966bbd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c3bdba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
